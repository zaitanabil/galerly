name: ðŸš€ Galerly Deployment Pipeline

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      clean_deployment:
        description: 'Complete AWS cleanup before deployment'
        required: false
        type: boolean
        default: false

env:
  AWS_REGION: us-east-1
  PYTHON_VERSION: '3.11'

# =============================================================================
# JOB FLOW:
# 1. validate â†’ 2. setup-infrastructure â†’ 3. deploy (backend/image/frontend) â†’ 4. verify
# Optional: cleanup-aws (runs independently when requested)
# =============================================================================

jobs:
  # ===========================================================================
  # OPTIONAL: AWS CLEANUP (Independent job)
  # ===========================================================================
  cleanup-aws:
    name: ðŸ§¹ AWS Cleanup
    runs-on: ubuntu-latest
    if: github.event.inputs.clean_deployment == 'true' || contains(github.event.head_commit.message, '[clean-deploy]')
    
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Delete Lambda Functions
        continue-on-error: true
        run: |
          echo "Removing Lambda functions..."
          for func in $(aws lambda list-functions --query 'Functions[?starts_with(FunctionName, `galerly`)].FunctionName' --output text); do
            echo "  Deleting: $func"
            aws lambda delete-function --function-name $func 2>/dev/null || true
          done

      - name: Empty S3 Buckets
        continue-on-error: true
        run: |
          echo "Emptying S3 buckets..."
          for bucket in $(aws s3api list-buckets --query 'Buckets[?starts_with(Name, `galerly`)].Name' --output text); do
            echo "  Emptying: $bucket"
            aws s3 rm s3://$bucket --recursive 2>/dev/null || true
          done

      - name: Delete DynamoDB Tables
        continue-on-error: true
        run: |
          echo "Removing DynamoDB tables..."
          for table in $(aws dynamodb list-tables --query 'TableNames[?starts_with(@, `galerly`)]' --output text); do
            echo "  Deleting: $table"
            aws dynamodb delete-table --table-name $table 2>/dev/null || true
          done

  # ===========================================================================
  # STAGE 1: VALIDATION
  # ===========================================================================
  validate:
    name: ðŸ” Validate Configuration
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Validate Secrets
        run: |
          echo "Checking required secrets..."
          MISSING_SECRETS=()
          
          # Core AWS
          [ -z "${{ secrets.AWS_ACCESS_KEY_ID }}" ] && MISSING_SECRETS+=("AWS_ACCESS_KEY_ID")
          [ -z "${{ secrets.AWS_SECRET_ACCESS_KEY }}" ] && MISSING_SECRETS+=("AWS_SECRET_ACCESS_KEY")
          
          # Application
          [ -z "${{ secrets.FRONTEND_URL }}" ] && MISSING_SECRETS+=("FRONTEND_URL")
          [ -z "${{ secrets.JWT_SECRET }}" ] && MISSING_SECRETS+=("JWT_SECRET")
          
          # S3 Buckets
          [ -z "${{ secrets.S3_BUCKET }}" ] && MISSING_SECRETS+=("S3_BUCKET")
          [ -z "${{ secrets.S3_PHOTOS_BUCKET }}" ] && MISSING_SECRETS+=("S3_PHOTOS_BUCKET")
          
          # DynamoDB Tables
          [ -z "${{ secrets.DYNAMODB_TABLE_USERS }}" ] && MISSING_SECRETS+=("DYNAMODB_TABLE_USERS")
          [ -z "${{ secrets.DYNAMODB_TABLE_GALLERIES }}" ] && MISSING_SECRETS+=("DYNAMODB_TABLE_GALLERIES")
          [ -z "${{ secrets.DYNAMODB_TABLE_PHOTOS }}" ] && MISSING_SECRETS+=("DYNAMODB_TABLE_PHOTOS")
          
          # Stripe
          [ -z "${{ secrets.STRIPE_SECRET_KEY }}" ] && MISSING_SECRETS+=("STRIPE_SECRET_KEY")
          
          # Lambda
          [ -z "${{ secrets.LAMBDA_FUNCTION_NAME }}" ] && MISSING_SECRETS+=("LAMBDA_FUNCTION_NAME")
          
          if [ ${#MISSING_SECRETS[@]} -gt 0 ]; then
            echo "âŒ Missing required secrets:"
            printf '  - %s\n' "${MISSING_SECRETS[@]}"
            exit 1
          fi
          
          echo "âœ… All required secrets present"

      - name: Validate Python Syntax
        run: |
          cd backend
          python -m py_compile api.py setup_dynamodb.py setup_aws.py configure_s3_lifecycle.py

  # ===========================================================================
  # STAGE 2: INFRASTRUCTURE SETUP
  # ===========================================================================
  setup-infrastructure:
    name: âš™ï¸ Setup AWS Infrastructure
    runs-on: ubuntu-latest
    needs: [validate]
    
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Dependencies
        run: |
          cd backend
          pip install boto3 python-dotenv

      - name: Configure AWS
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Create DynamoDB Tables
        run: |
          cd backend
          python setup_dynamodb.py create

      - name: Configure S3 Buckets
        run: |
          # Frontend bucket
          if ! aws s3 ls s3://${{ secrets.S3_BUCKET }} 2>/dev/null; then
            aws s3 mb s3://${{ secrets.S3_BUCKET }} --region ${{ env.AWS_REGION }}
            aws s3 website s3://${{ secrets.S3_BUCKET }} --index-document index.html --error-document 404.html
            
            # Public read policy
            aws s3api put-bucket-policy --bucket ${{ secrets.S3_BUCKET }} --policy "{
              \"Version\": \"2012-10-17\",
              \"Statement\": [{
                \"Sid\": \"PublicRead\",
                \"Effect\": \"Allow\",
                \"Principal\": \"*\",
                \"Action\": \"s3:GetObject\",
                \"Resource\": \"arn:aws:s3:::${{ secrets.S3_BUCKET }}/*\"
              }]
            }"
          fi
          
          # Photos bucket
          if ! aws s3 ls s3://${{ secrets.S3_PHOTOS_BUCKET }} 2>/dev/null; then
            aws s3 mb s3://${{ secrets.S3_PHOTOS_BUCKET }} --region ${{ env.AWS_REGION }}
          fi
          
          # Renditions bucket
          if ! aws s3 ls s3://galerly-renditions 2>/dev/null; then
            aws s3 mb s3://galerly-renditions --region ${{ env.AWS_REGION }}
            
            # Public read for CDN
            aws s3api put-bucket-policy --bucket galerly-renditions --policy "{
              \"Version\": \"2012-10-17\",
              \"Statement\": [{
                \"Sid\": \"PublicRead\",
                \"Effect\": \"Allow\",
                \"Principal\": \"*\",
                \"Action\": \"s3:GetObject\",
                \"Resource\": \"arn:aws:s3:::galerly-renditions/*\"
              }]
            }"
          fi

      - name: Configure CORS (setup_aws.py)
        env:
          S3_PHOTOS_BUCKET: ${{ secrets.S3_PHOTOS_BUCKET }}
          FRONTEND_URL: ${{ secrets.FRONTEND_URL }}
        run: |
          cd backend
          python setup_aws.py s3-cors

      - name: Configure S3 Lifecycle Policies
        env:
          S3_PHOTOS_BUCKET: ${{ secrets.S3_PHOTOS_BUCKET }}
        run: |
          cd backend
          python configure_s3_lifecycle.py

  # ===========================================================================
  # STAGE 3: DEPLOY BACKEND
  # ===========================================================================
  deploy-backend:
    name: âš¡ Deploy Backend Lambda
    runs-on: ubuntu-latest
    needs: [setup-infrastructure]
    
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Configure AWS
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Build Lambda Package
        run: |
          cd backend
          
          # Install lightweight dependencies (excluding image libs)
          pip install boto3 stripe python-dotenv requests beautifulsoup4 lxml -t package/
          
          # Copy application code
          cp api.py package/
          cp -r handlers package/
          cp -r utils package/
          
          # Create deployment package
          cd package
          zip -r ../lambda-deployment.zip . -q
          cd ..
          zip -g lambda-deployment.zip scheduled_lambda.py

      - name: Deploy/Update Lambda Function
        run: |
          cd backend
          
          # Check if function exists
          if aws lambda get-function --function-name ${{ secrets.LAMBDA_FUNCTION_NAME }} 2>/dev/null; then
            echo "Updating existing function..."
            aws lambda update-function-code \
              --function-name ${{ secrets.LAMBDA_FUNCTION_NAME }} \
              --zip-file fileb://lambda-deployment.zip
            
            # Wait for update
            aws lambda wait function-updated --function-name ${{ secrets.LAMBDA_FUNCTION_NAME }}
            
            # Update environment variables
            aws lambda update-function-configuration \
              --function-name ${{ secrets.LAMBDA_FUNCTION_NAME }} \
              --environment "Variables={
                JWT_SECRET=${{ secrets.JWT_SECRET }},
                FRONTEND_URL=${{ secrets.FRONTEND_URL }},
                S3_PHOTOS_BUCKET=${{ secrets.S3_PHOTOS_BUCKET }},
                DYNAMODB_TABLE_USERS=${{ secrets.DYNAMODB_TABLE_USERS }},
                DYNAMODB_TABLE_GALLERIES=${{ secrets.DYNAMODB_TABLE_GALLERIES }},
                DYNAMODB_TABLE_PHOTOS=${{ secrets.DYNAMODB_TABLE_PHOTOS }},
                STRIPE_SECRET_KEY=${{ secrets.STRIPE_SECRET_KEY }}
              }"
          else
            echo "âŒ Lambda function not found. Please create it manually first."
            exit 1
          fi

  # ===========================================================================
  # STAGE 4: DEPLOY IMAGE PROCESSING
  # ===========================================================================
  deploy-image-processing:
    name: ðŸ–¼ï¸ Deploy Image Processing
    runs-on: ubuntu-latest
    needs: [setup-infrastructure]
    
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Configure AWS
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Deploy Image Processing Lambda
        run: |
          cd backend/image-processing
          chmod +x deploy.sh
          ./deploy.sh

  # ===========================================================================
  # STAGE 5: DEPLOY FRONTEND
  # ===========================================================================
  deploy-frontend:
    name: ðŸŒ Deploy Frontend
    runs-on: ubuntu-latest
    needs: [deploy-backend]
    
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Deploy Frontend to S3
        run: |
          aws s3 sync frontend/ s3://${{ secrets.S3_BUCKET }}/ \
            --delete \
            --cache-control "public, max-age=31536000" \
            --exclude "*.html" \
            --exclude "*.txt"
          
          # HTML files with shorter cache
          aws s3 sync frontend/ s3://${{ secrets.S3_BUCKET }}/ \
            --exclude "*" \
            --include "*.html" \
            --cache-control "public, max-age=3600"

      - name: Invalidate CloudFront Cache
        if: secrets.CLOUDFRONT_DISTRIBUTION_ID != ''
        run: |
          aws cloudfront create-invalidation \
            --distribution-id ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }} \
            --paths "/*"

  # ===========================================================================
  # STAGE 6: VERIFICATION
  # ===========================================================================
  verify:
    name: âœ… Verify Deployment
    runs-on: ubuntu-latest
    needs: [deploy-backend, deploy-image-processing, deploy-frontend]
    
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Configure AWS
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Run Verification Tests
        run: |
          cd backend
          pip install boto3 pytest requests
          
          # Run smoke tests
          python -m pytest tests/test_smoke.py -v || true

      - name: Verify DynamoDB Tables
        run: |
          echo "Checking DynamoDB tables..."
          for table in ${{ secrets.DYNAMODB_TABLE_USERS }} ${{ secrets.DYNAMODB_TABLE_GALLERIES }} ${{ secrets.DYNAMODB_TABLE_PHOTOS }}; do
            if aws dynamodb describe-table --table-name $table >/dev/null 2>&1; then
              echo "  âœ… $table"
            else
              echo "  âŒ $table not found"
            fi
          done

      - name: Verify S3 Buckets
        run: |
          echo "Checking S3 buckets..."
          for bucket in ${{ secrets.S3_BUCKET }} ${{ secrets.S3_PHOTOS_BUCKET }} galerly-renditions; do
            if aws s3 ls s3://$bucket >/dev/null 2>&1; then
              echo "  âœ… $bucket"
            else
              echo "  âŒ $bucket not accessible"
            fi
          done

  # ===========================================================================
  # STAGE 7: SUMMARY
  # ===========================================================================
  summary:
    name: ðŸ“Š Deployment Summary
    runs-on: ubuntu-latest
    needs: [verify]
    if: always()
    
    steps:
      - name: Generate Summary
        run: |
          cat >> $GITHUB_STEP_SUMMARY << 'EOFSUMMARY'
          # ðŸŽ‰ Galerly Deployment Complete
          
          ## Components Deployed
          | Component | Status |
          |-----------|--------|
          | Frontend (S3) | âœ… Deployed |
          | Backend (Lambda) | âœ… Updated |
          | Image Processing | âœ… Deployed |
          | DynamoDB Tables | âœ… Ready |
          | S3 Storage | âœ… Configured |
          
          ## Next Steps
          1. Visit: ${{ secrets.FRONTEND_URL }}
          2. Test photo upload
          3. Verify image processing
          4. Check CloudWatch logs
          
          ## Useful Commands
          ```bash
          # View Lambda logs
          aws logs tail /aws/lambda/${{ secrets.LAMBDA_FUNCTION_NAME }} --follow
          
          # Check DynamoDB
          aws dynamodb scan --table-name ${{ secrets.DYNAMODB_TABLE_GALLERIES }} --max-items 5
          
          # Monitor S3
          aws s3 ls s3://${{ secrets.S3_PHOTOS_BUCKET }}/
          ```
          EOFSUMMARY
